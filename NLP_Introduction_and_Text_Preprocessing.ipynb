{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3d62d983",
      "metadata": {
        "id": "3d62d983"
      },
      "source": [
        "## NLP Introduction and Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e74f8a2f",
      "metadata": {
        "id": "e74f8a2f"
      },
      "outputs": [],
      "source": [
        "# Q1. What is the primary goal of Natural Language Processing (NLP)?\n",
        "\n",
        "# answer\n",
        "# Enable computers to understand, interpret, and generate human language for useful tasks (translation, QA, summarization, etc.).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7810c3a",
      "metadata": {
        "id": "d7810c3a"
      },
      "outputs": [],
      "source": [
        "# Q2. What does \"tokenization\" refer to in text processing?\n",
        "\n",
        "# answer\n",
        "# Splitting text into smaller units (tokens) such as words or sentences for further processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "837102b7",
      "metadata": {
        "id": "837102b7"
      },
      "outputs": [],
      "source": [
        "# Q3. What is the difference between lemmatization and stemming?\n",
        "\n",
        "# answer\n",
        "# Stemming crudely trims word endings; lemmatization returns the dictionary base form using vocabulary and POS.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caf83fed",
      "metadata": {
        "id": "caf83fed"
      },
      "outputs": [],
      "source": [
        "# Q4. What is the role of regular expressions (regex) in text processing?\n",
        "\n",
        "# answer\n",
        "# Pattern matching for cleaning, extraction (emails, URLs), and text normalization tasks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3019c70d",
      "metadata": {
        "id": "3019c70d"
      },
      "outputs": [],
      "source": [
        "# Q5. What is Word2Vec and how does it represent words in a vector space?\n",
        "\n",
        "# answer\n",
        "# A neural method that learns dense continuous vectors so semantically similar words are close in vector space.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ce202be",
      "metadata": {
        "id": "1ce202be"
      },
      "outputs": [],
      "source": [
        "# Q6. How does frequency distribution help in text analysis?\n",
        "\n",
        "# answer\n",
        "# Shows term occurrence counts; useful for exploratory analysis, stopword detection, and feature selection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a76a2cdb",
      "metadata": {
        "id": "a76a2cdb"
      },
      "outputs": [],
      "source": [
        "# Q7. Why is text normalization important in NLP?\n",
        "\n",
        "# answer\n",
        "# Reduces variability (case, punctuation) to create consistent tokens and improve model performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03e16d8a",
      "metadata": {
        "id": "03e16d8a"
      },
      "outputs": [],
      "source": [
        "# Q8. What is the difference between sentence tokenization and word tokenization?\n",
        "\n",
        "# answer\n",
        "# Sentence tokenization splits text into sentences; word tokenization splits sentences into words/tokens.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35082cb2",
      "metadata": {
        "id": "35082cb2"
      },
      "outputs": [],
      "source": [
        "# Q9. What are co-occurrence vectors in NLP?\n",
        "\n",
        "# answer\n",
        "# Vectors capturing counts of words appearing together within a context window, representing relationships.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b93da200",
      "metadata": {
        "id": "b93da200"
      },
      "outputs": [],
      "source": [
        "# Q10. What is the significance of lemmatization in improving NLP tasks?\n",
        "\n",
        "# answer\n",
        "# Reduces inflectional variants, lowering sparsity and improving matching across forms.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c93836a",
      "metadata": {
        "id": "6c93836a"
      },
      "outputs": [],
      "source": [
        "# Q11. What is the primary use of word embeddings in NLP?\n",
        "\n",
        "# answer\n",
        "# To provide dense numerical representations of words capturing semantics for ML models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d11535f",
      "metadata": {
        "id": "9d11535f"
      },
      "outputs": [],
      "source": [
        "# Q12. What is an annotator in NLP?\n",
        "\n",
        "# answer\n",
        "# A component or tool that adds labels (POS, NER, syntax) to text for training or analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe82b493",
      "metadata": {
        "id": "fe82b493"
      },
      "outputs": [],
      "source": [
        "# Q13. What are the key steps in text processing before applying machine learning models?\n",
        "\n",
        "# answer\n",
        "# Tokenization, cleaning, normalization, stopword removal, stemming/lemmatization, and vectorization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "841d2050",
      "metadata": {
        "id": "841d2050"
      },
      "outputs": [],
      "source": [
        "# Q14. What is the history of NLP and how has it evolved?\n",
        "\n",
        "# answer\n",
        "# From rule-based systems to statistical ML to modern deep learning (embeddings, transformers).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e780152",
      "metadata": {
        "id": "6e780152"
      },
      "outputs": [],
      "source": [
        "# Q15. Why is sentence processing important in NLP?\n",
        "\n",
        "# answer\n",
        "# It keeps local context needed for tasks like parsing, translation, and sentence-level classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21b30d53",
      "metadata": {
        "id": "21b30d53"
      },
      "outputs": [],
      "source": [
        "# Q16. How do word embeddings improve the understanding of language semantics in NLP?\n",
        "\n",
        "# answer\n",
        "# By encoding semantic relatedness and syntactic properties in dense vectors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec6dde29",
      "metadata": {
        "id": "ec6dde29"
      },
      "outputs": [],
      "source": [
        "# Q17. How does the frequency distribution of words help in text classification?\n",
        "\n",
        "# answer\n",
        "# Highlights discriminative words and supports feature engineering and selection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e0fcc02",
      "metadata": {
        "id": "0e0fcc02"
      },
      "outputs": [],
      "source": [
        "# Q18. What are the advantages of using regex in text cleaning?\n",
        "\n",
        "# answer\n",
        "# Regex is flexible, fast for pattern-based cleaning and extraction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb989328",
      "metadata": {
        "id": "cb989328"
      },
      "outputs": [],
      "source": [
        "# Q19. What is the difference between word2vec and doc2vec?\n",
        "\n",
        "# answer\n",
        "# Word2Vec produces word vectors; Doc2Vec produces document vectors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd0527c9",
      "metadata": {
        "id": "cd0527c9"
      },
      "outputs": [],
      "source": [
        "# Q20. Why is understanding text normalization important in NLP?\n",
        "\n",
        "# answer\n",
        "# Normalization reduces noise and makes downstream features more consistent.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbf806e6",
      "metadata": {
        "id": "fbf806e6"
      },
      "outputs": [],
      "source": [
        "# Q21. How does word count help in text analysis?\n",
        "\n",
        "# answer\n",
        "# Provides simple frequency features for analysis and basic models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd923fb8",
      "metadata": {
        "id": "fd923fb8"
      },
      "outputs": [],
      "source": [
        "# Q22. How does lemmatization help in NLP tasks like search engines and chatbots?\n",
        "\n",
        "# answer\n",
        "# Maps inflected words to base forms so queries and intents match more reliably.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "583c2844",
      "metadata": {
        "id": "583c2844"
      },
      "outputs": [],
      "source": [
        "# Q23. What is the purpose of using Doc2Vec in text processing?\n",
        "\n",
        "# answer\n",
        "# To get fixed-size vectors representing whole documents for retrieval and classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3a604ae",
      "metadata": {
        "id": "b3a604ae"
      },
      "outputs": [],
      "source": [
        "# Q24. What is the importance of sentence processing in NLP?\n",
        "\n",
        "# answer\n",
        "# Preserves sentence-level meaning and structure important for many tasks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c11f26c3",
      "metadata": {
        "id": "c11f26c3"
      },
      "outputs": [],
      "source": [
        "# Q25. What is text normalization, and what are the common techniques used in it?\n",
        "\n",
        "# answer\n",
        "# Lowercasing, removing punctuation, expanding contractions, and unicode normalization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fb45b5b",
      "metadata": {
        "id": "1fb45b5b"
      },
      "outputs": [],
      "source": [
        "# Q26. Why is word tokenization important in NLP?\n",
        "\n",
        "# answer\n",
        "# It defines tokens used for feature extraction, embeddings and analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "471f4f08",
      "metadata": {
        "id": "471f4f08"
      },
      "outputs": [],
      "source": [
        "# Q27. How does sentence tokenization differ from word tokenization in NLP?\n",
        "\n",
        "# answer\n",
        "# They operate at different granularities and are used in different preprocessing steps.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81631dc8",
      "metadata": {
        "id": "81631dc8"
      },
      "outputs": [],
      "source": [
        "# Q28. What is the primary purpose of text processing in NLP?\n",
        "\n",
        "# answer\n",
        "# To convert raw text into structured features suitable for ML models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1a2c0f3",
      "metadata": {
        "id": "e1a2c0f3"
      },
      "outputs": [],
      "source": [
        "# Q29. What are the key challenges in NLP?\n",
        "\n",
        "# answer\n",
        "# Ambiguity, data sparsity, domain shift, multilinguality, and contextual understanding.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14d6e280",
      "metadata": {
        "id": "14d6e280"
      },
      "outputs": [],
      "source": [
        "# Q30. How do co-occurrence vectors represent relationships between words?\n",
        "\n",
        "# answer\n",
        "# By counting nearby word occurrences; association metrics like PMI quantify relationships.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7be49845",
      "metadata": {
        "id": "7be49845"
      },
      "outputs": [],
      "source": [
        "# Q31. What is the role of frequency distribution in text analysis?\n",
        "\n",
        "# answer\n",
        "# Reveals common terms and guides feature selection and cleaning decisions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a8d3b93",
      "metadata": {
        "id": "1a8d3b93"
      },
      "outputs": [],
      "source": [
        "# Q32. What is the impact of word embeddings on NLP tasks?\n",
        "\n",
        "# answer\n",
        "# They improved generalization and enabled semantic-aware features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbe6b248",
      "metadata": {
        "id": "bbe6b248"
      },
      "outputs": [],
      "source": [
        "# Q33. What is the purpose of using lemmatization in text preprocessing?\n",
        "\n",
        "# answer\n",
        "# To reduce vocabulary size and group inflected forms under base lemmas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8308bce8",
      "metadata": {
        "id": "8308bce8"
      },
      "source": [
        "## Practical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2e0c3d90",
      "metadata": {
        "id": "2e0c3d90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f97154c1-f4d9-4588-8439-88930064de13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural', 'Language', 'Processing', 'with', 'NLTK', 'is', 'fun', 'and', 'powerful', '.']\n"
          ]
        }
      ],
      "source": [
        "# Q1. How can you perform word tokenization using NLTK\n",
        "\n",
        "#code >\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download required data\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')  # Newly required in recent NLTK versions\n",
        "\n",
        "# Sample text\n",
        "text = \"Natural Language Processing with NLTK is fun and powerful.\"\n",
        "\n",
        "# Perform word tokenization\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "#example >\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e703f177",
      "metadata": {
        "id": "e703f177",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3022ea0e-9f25-4d02-e849-8d6cc4d95aa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural Language Processing with NLTK is fun.', 'It allows sentence and word tokenization.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Q2. How can you perform sentence tokenization using NLTK\n",
        "\n",
        "#code >\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Download required data\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')  # Prevents punkt_tab error in new NLTK versions\n",
        "\n",
        "# Sample text\n",
        "text = \"Natural Language Processing with NLTK is fun. It allows sentence and word tokenization.\"\n",
        "\n",
        "# Perform sentence tokenization\n",
        "sentences = sent_tokenize(text)\n",
        "\n",
        "#example >\n",
        "print(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "acfef5b3",
      "metadata": {
        "id": "acfef5b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "534ea13d-bc0e-4f2f-e848-abcf2751fe4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['example', 'showing', 'remove', 'stopwords', 'sentence', 'using', 'NLTK', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# Q3. How can you remove stopwords from a sentence\n",
        "\n",
        "#code >\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download required datasets\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')  # Fix for newer NLTK versions\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Sample sentence\n",
        "sentence = \"This is an example showing how to remove stopwords from a sentence using NLTK.\"\n",
        "\n",
        "# Tokenize the sentence\n",
        "words = word_tokenize(sentence)\n",
        "\n",
        "# Get English stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Remove stopwords\n",
        "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "\n",
        "#example >\n",
        "print(filtered_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1d59012",
      "metadata": {
        "id": "b1d59012",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34df2b60-54c0-44f3-c947-346b5673b4a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run\n"
          ]
        }
      ],
      "source": [
        "# Q4. How can you perform stemming on a word\n",
        "\n",
        "# code >\n",
        "import nltk\n",
        "nltk.download('punkt', quiet=True)\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "def stem_word(word):\n",
        "    ps = PorterStemmer()\n",
        "    return ps.stem(word)\n",
        "\n",
        "# example\n",
        "print(stem_word(\"running\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a47b5397",
      "metadata": {
        "id": "a47b5397",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ebc3fa2-8789-435e-f1e4-ec9635cf1b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run\n"
          ]
        }
      ],
      "source": [
        "# Q5. How can you perform lemmatization on a word\n",
        "\n",
        "# code >\n",
        "import nltk\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "def lemmatize_word(word, pos='n'):\n",
        "    wn = WordNetLemmatizer()\n",
        "    return wn.lemmatize(word, pos=pos)\n",
        "\n",
        "# example\n",
        "print(lemmatize_word(\"running\", pos='v'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27141479",
      "metadata": {
        "id": "27141479",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "595dc1e2-971c-4665-c27c-a0e6cf051884"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello world this is sample text\n"
          ]
        }
      ],
      "source": [
        "# Q6. How can you normalize a text by converting it to lowercase and removing punctuation\n",
        "\n",
        "# code >\n",
        "import re\n",
        "def normalize_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "# example\n",
        "print(normalize_text(\"Hello, World! This is SAMPLE text.\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb854293",
      "metadata": {
        "id": "eb854293",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fb14d2a-a9c3-419f-d1c0-618c77135551"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([[0, 1, 0, 0, 0],\n",
            "       [1, 0, 1, 0, 0],\n",
            "       [0, 1, 0, 1, 0],\n",
            "       [0, 0, 1, 0, 1],\n",
            "       [0, 0, 0, 1, 0]]), {'i': 0, 'love': 1, 'nlp': 2, 'is': 3, 'fun': 4})\n"
          ]
        }
      ],
      "source": [
        "# Q7. How can you create a co-occurrence matrix for words in a corpus\n",
        "\n",
        "# code >\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "def cooccurrence_matrix(corpus, window=1):\n",
        "    vocab = {}\n",
        "    idx = 0\n",
        "    for sent in corpus:\n",
        "        for token in sent:\n",
        "            if token not in vocab:\n",
        "                vocab[token] = idx\n",
        "                idx += 1\n",
        "    V = len(vocab)\n",
        "    mat = np.zeros((V, V), dtype=int)\n",
        "    for sent in corpus:\n",
        "        for i, token in enumerate(sent):\n",
        "            for j in range(max(0, i-window), min(len(sent), i+window+1)):\n",
        "                if i == j: continue\n",
        "                mat[vocab[token], vocab[sent[j]]] += 1\n",
        "    return mat, vocab\n",
        "\n",
        "# example\n",
        "corpus = [['i','love','nlp'], ['nlp','is','fun']]\n",
        "print(cooccurrence_matrix(corpus, window=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d14210d",
      "metadata": {
        "id": "4d14210d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00b9e2d0-c7ad-4cc5-a388-526437cfa978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['test@example.com', 'admin@domain.org']\n"
          ]
        }
      ],
      "source": [
        "# Q8. How can you apply a regular expression to extract all email addresses from a text\n",
        "\n",
        "# code >\n",
        "import re\n",
        "def extract_emails(text):\n",
        "    pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
        "    return re.findall(pattern, text)\n",
        "\n",
        "# example\n",
        "print(extract_emails(\"Contact us at test@example.com or admin@domain.org\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b2216b96",
      "metadata": {
        "id": "b2216b96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05a9f319-398c-430a-bfdd-24cbb2c8a781"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector for 'word2vec':\n",
            "[ 0.00805391  0.00869487  0.01991474 -0.00894748 -0.00277853 -0.01463464\n",
            " -0.01939566 -0.01816051 -0.00204551 -0.01300658  0.00969946 -0.01232805\n",
            "  0.00503837  0.00147888 -0.00678431 -0.00195845  0.01995825  0.01829177\n",
            " -0.00892366  0.01816605 -0.01128353  0.01186184 -0.00619444  0.0068635\n",
            "  0.00603445  0.01380092 -0.00474777  0.01755007  0.01517886 -0.01909529\n",
            " -0.01601642 -0.01527579  0.00584651 -0.00558944 -0.01385904 -0.01625653\n",
            "  0.01661836  0.00398098 -0.01865603 -0.00958543  0.00627348 -0.00942641\n",
            "  0.01056169 -0.00846688  0.00528359 -0.01609137  0.01241977  0.00963778\n",
            "  0.00157439  0.0060269 ]\n"
          ]
        }
      ],
      "source": [
        "# Q9. How can you perform word embedding using Word2Vec\n",
        "\n",
        "#code >\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Sample corpus\n",
        "sentences = [\n",
        "    [\"this\", \"is\", \"a\", \"sample\", \"sentence\"],\n",
        "    [\"word2vec\", \"is\", \"a\", \"word\", \"embedding\", \"technique\"],\n",
        "    [\"we\", \"are\", \"learning\", \"nlp\"]\n",
        "]\n",
        "\n",
        "# Train a Word2Vec model\n",
        "model = Word2Vec(sentences, vector_size=50, window=3, min_count=1, sg=0)  # sg=0 means CBOW model\n",
        "\n",
        "# Get the vector for a specific word\n",
        "vector = model.wv['word2vec']\n",
        "\n",
        "#example >\n",
        "print(\"Vector for 'word2vec':\")\n",
        "print(vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9f89ef41",
      "metadata": {
        "id": "9f89ef41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b77fb27-6eef-4131-efc0-fe53821dec12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.02617465 -0.02991903 -0.04944214  0.04279845  0.01784391  0.00131578\n",
            " -0.04944142 -0.02585304 -0.0486283   0.01006166  0.01416314  0.02323591\n",
            " -0.02150346 -0.01574047 -0.01540617 -0.04364383  0.01087098  0.04616427\n",
            " -0.04754711 -0.01730448]\n"
          ]
        }
      ],
      "source": [
        "# Q10. How can you use Doc2Vec to embed documents\n",
        "\n",
        "# code >\n",
        "# Requires: pip install gensim\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "def train_doc2vec(docs, vector_size=50, epochs=20):\n",
        "    tagged = [TaggedDocument(words=d.split(), tags=[str(i)]) for i, d in enumerate(docs)]\n",
        "    model = Doc2Vec(tagged, vector_size=vector_size, epochs=epochs, min_count=1)\n",
        "    return model\n",
        "\n",
        "# example\n",
        "d2v = train_doc2vec(['this is doc one', 'another doc'], vector_size=20, epochs=10)\n",
        "print(d2v.dv['0'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "61955808",
      "metadata": {
        "id": "61955808",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a52402c-30fe-4149-f847-e50f85d91c1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Part-of-Speech Tags:\n",
            "[('NLTK', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('great', 'JJ'), ('library', 'NN'), ('for', 'IN'), ('text', 'NN'), ('processing', 'NN')]\n"
          ]
        }
      ],
      "source": [
        "# Q11. How can you perform part-of-speech tagging\n",
        "\n",
        "#code >\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "# Sample sentence\n",
        "text = \"NLTK is a great library for text processing\"\n",
        "\n",
        "# Tokenize sentence\n",
        "words = nltk.word_tokenize(text)\n",
        "\n",
        "# Perform POS tagging\n",
        "pos_tags = nltk.pos_tag(words)\n",
        "\n",
        "#example >\n",
        "print(\"Part-of-Speech Tags:\")\n",
        "print(pos_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4fdc0e7",
      "metadata": {
        "id": "e4fdc0e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e60c196b-046b-462a-f4c4-5e662e768a5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7765145304745156\n"
          ]
        }
      ],
      "source": [
        "# Q12. How can you find the similarity between two sentences using cosine similarity\n",
        "\n",
        "# code >\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def sentence_cosine_similarity(s1, s2):\n",
        "    vect = TfidfVectorizer().fit_transform([s1, s2])\n",
        "    return cosine_similarity(vect[0:1], vect[1:2])[0][0]\n",
        "\n",
        "# example\n",
        "print(sentence_cosine_similarity(\"This is a test\", \"This test is simple\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5567fcb",
      "metadata": {
        "id": "a5567fcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dad1915a-9898-4644-b9af-68d81dca1dde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Barack Obama', 'PERSON'), ('Hawaii', 'GPE')]\n"
          ]
        }
      ],
      "source": [
        "# Q13. How can you extract named entities from a sentence\n",
        "\n",
        "# code >\n",
        "# Requires: pip install spacy && python -m spacy download en_core_web_sm\n",
        "import spacy\n",
        "def extract_entities(text, model_name='en_core_web_sm'):\n",
        "    nlp = spacy.load(model_name)\n",
        "    doc = nlp(text)\n",
        "    return [(ent.text, ent.label_) for ent in doc.ents]\n",
        "\n",
        "# example\n",
        "print(extract_entities(\"Barack Obama was born in Hawaii.\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74f993d8",
      "metadata": {
        "id": "74f993d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0be595b4-1817-420a-f31c-60d67b7fb0f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This is a sample large text This is a sample', 'large text This is a sample large text This is']\n"
          ]
        }
      ],
      "source": [
        "# Q14. How can you split a large document into smaller chunks of text\n",
        "\n",
        "# code >\n",
        "def chunk_text(text, chunk_size=200):\n",
        "    words = text.split()\n",
        "    for i in range(0, len(words), chunk_size):\n",
        "        yield \" \".join(words[i:i+chunk_size])\n",
        "\n",
        "# example\n",
        "print(list(chunk_text(\"This is a sample large text \" * 50, chunk_size=10))[:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d4a3051",
      "metadata": {
        "id": "1d4a3051",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a98cab59-c471-4ab1-fa2c-3b157843e40b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['another' 'doc' 'is' 'this']\n"
          ]
        }
      ],
      "source": [
        "# Q15. How can you calculate the TF-IDF (Term Frequency - Inverse Document Frequency) for a set of documents\n",
        "\n",
        "# code >\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def compute_tfidf(docs):\n",
        "    vect = TfidfVectorizer()\n",
        "    tfidf = vect.fit_transform(docs)\n",
        "    return tfidf, vect.get_feature_names_out()\n",
        "\n",
        "# example\n",
        "tfidf, feature_names = compute_tfidf([\"this is a doc\", \"this is another doc\"])\n",
        "print(feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cfd34a93",
      "metadata": {
        "id": "cfd34a93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "314795ef-0350-4294-9dc1-bd6ed6635319"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['exampl', 'show', 'token', 'stopword', 'remov', 'stem']\n"
          ]
        }
      ],
      "source": [
        "# Q16. How can you apply tokenization, stopword removal, and stemming in one go\n",
        "\n",
        "# code >\n",
        "import nltk\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def full_preprocess(text):\n",
        "    ps = PorterStemmer()\n",
        "    stops = set(stopwords.words('english'))\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    return [ps.stem(t) for t in tokens if t.isalpha() and t not in stops]\n",
        "\n",
        "# example\n",
        "print(full_preprocess(\"This is an example showing tokenization, stopwords removal, and stemming.\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8964f3a5",
      "metadata": {
        "id": "8964f3a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "e1bfd36b-5e64-477c-92c9-bea896f7156b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Q17. How can you visualize the frequency distribution of words in a sentence?\n",
        "\n",
        "# code >\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def plot_freq_distribution(text, top_n=10):\n",
        "    tokens = [t.lower() for t in word_tokenize(text) if t.isalpha()]\n",
        "    freq = Counter(tokens)\n",
        "    common = freq.most_common(top_n)\n",
        "    words, counts = zip(*common) if common else ([],[])\n",
        "    plt.bar(words, counts)\n",
        "    plt.title(\"Top words frequency\")\n",
        "    plt.show()\n",
        "\n",
        "# example\n",
        "plot_freq_distribution(\"This is a sample sentence with sample words sample sample.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AjHhnstbwM9b"
      },
      "id": "AjHhnstbwM9b",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}