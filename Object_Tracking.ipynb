{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Object Tracking"
      ],
      "metadata": {
        "id": "8S_uJ_m8tCq-"
      },
      "id": "8S_uJ_m8tCq-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "554ba9ca",
      "metadata": {
        "id": "554ba9ca"
      },
      "outputs": [],
      "source": [
        "# Q1. What is object tracking, and how does it differ from object detection?\n",
        "\n",
        "# answer\n",
        "# Object tracking is the process of locating and following the movement of objects over time in a video sequence.\n",
        "# It differs from object detection in that detection identifies and classifies objects in a single frame,\n",
        "# while tracking maintains the identity of those objects across multiple frames to understand motion and behavior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fb814ea",
      "metadata": {
        "id": "6fb814ea"
      },
      "outputs": [],
      "source": [
        "# Q2. Explain the basic working principle of a Kalman Filter.\n",
        "\n",
        "# answer\n",
        "# A Kalman Filter is an algorithm that estimates the state of a moving object by combining predictions from a motion model\n",
        "# and observations from noisy measurements. It has two main steps:\n",
        "# 1. Prediction step – estimates the current state based on the previous state and a motion model.\n",
        "# 2. Update step – refines the prediction using the latest observation, reducing uncertainty."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71dbf932",
      "metadata": {
        "id": "71dbf932"
      },
      "outputs": [],
      "source": [
        "# Q3. What is YOLO, and why is it popular for object detection in real-time application?\n",
        "\n",
        "# answer\n",
        "# YOLO (You Only Look Once) is a real-time object detection algorithm that treats detection as a single regression problem.\n",
        "# It predicts bounding boxes and class probabilities directly from full images in one evaluation,\n",
        "# making it extremely fast and efficient, which is why it’s popular for real-time applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9173b7ff",
      "metadata": {
        "id": "9173b7ff"
      },
      "outputs": [],
      "source": [
        "# Q4. How does DeepSORT improve object tracking?\n",
        "\n",
        "# answer\n",
        "# DeepSORT improves object tracking by adding deep appearance features to SORT’s motion-based tracking.\n",
        "# This helps the tracker to re-identify objects even after occlusion, enabling more robust and accurate multi-object tracking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0bd2920",
      "metadata": {
        "id": "d0bd2920"
      },
      "outputs": [],
      "source": [
        "# Q5. Explain the concept of state estimation in a Kalman Filter.\n",
        "\n",
        "# answer\n",
        "# State estimation in a Kalman Filter refers to predicting the most likely position, velocity, or other parameters of a moving object\n",
        "# given prior knowledge (previous state) and noisy measurements.\n",
        "# The Kalman Filter minimizes the mean squared error between the predicted and actual state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "992a79c6",
      "metadata": {
        "id": "992a79c6"
      },
      "outputs": [],
      "source": [
        "# Q6. What are the challenges in object tracking across multiple frames?\n",
        "\n",
        "# answer\n",
        "# Challenges include occlusion (objects blocking each other), changes in appearance (lighting, scale, angle),\n",
        "# motion blur, crowded scenes, camera movement, and false detections.\n",
        "# These factors can cause identity switches and tracking failures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bfc3321",
      "metadata": {
        "id": "4bfc3321"
      },
      "outputs": [],
      "source": [
        "# Q7. Describe the role of the Hungarian algorithm in DeepSORT.\n",
        "\n",
        "# answer\n",
        "# The Hungarian algorithm is used in DeepSORT to solve the assignment problem.\n",
        "# It matches detected objects in the current frame with existing tracked objects based on a cost matrix\n",
        "# that considers both motion and appearance features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df4b80d3",
      "metadata": {
        "id": "df4b80d3"
      },
      "outputs": [],
      "source": [
        "# Q8. What are the advantages of using YOLO over traditional object detection methods?\n",
        "\n",
        "# answer\n",
        "# Advantages include:\n",
        "# - High speed (real-time performance)\n",
        "# - Unified detection pipeline (single neural network pass)\n",
        "# - Good accuracy for many applications\n",
        "# - End-to-end training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bdebc67",
      "metadata": {
        "id": "7bdebc67"
      },
      "outputs": [],
      "source": [
        "# Q9. How does the Kalman Filter handle uncertainty in predictions?\n",
        "\n",
        "# answer\n",
        "# The Kalman Filter uses covariance matrices to represent uncertainty.\n",
        "# In the update step, it adjusts the prediction by weighting the measurement and the prediction based on their respective uncertainties,\n",
        "# giving more weight to the more reliable source."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b0ff13c",
      "metadata": {
        "id": "5b0ff13c"
      },
      "outputs": [],
      "source": [
        "# Q10. What is the difference between object tracking and object segmentation?\n",
        "\n",
        "# answer\n",
        "# Object tracking focuses on locating and following an object across frames using bounding boxes.\n",
        "# Object segmentation identifies the exact pixels that belong to an object in each frame,\n",
        "# providing more precise shape and boundary information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29870e06",
      "metadata": {
        "id": "29870e06"
      },
      "outputs": [],
      "source": [
        "# Q11. How can YOLO be used in combination with a Kalman Filter for tracking?\n",
        "\n",
        "# answer\n",
        "# YOLO can be used to detect objects in each frame,\n",
        "# and the Kalman Filter can predict the position of those objects in the next frame,\n",
        "# ensuring smooth tracking even when detections are missed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52be5084",
      "metadata": {
        "id": "52be5084"
      },
      "outputs": [],
      "source": [
        "# Q12. What are the key components of DeepSORT?\n",
        "\n",
        "# answer\n",
        "# Key components include:\n",
        "# - Motion model (Kalman Filter)\n",
        "# - Appearance descriptor (deep feature extractor)\n",
        "# - Data association algorithm (Hungarian algorithm)\n",
        "# - Track management logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25c6d6cb",
      "metadata": {
        "id": "25c6d6cb"
      },
      "outputs": [],
      "source": [
        "# Q13. Explain the process of associating detections with existing tracks in DeepSORT.\n",
        "\n",
        "# answer\n",
        "# DeepSORT creates a cost matrix combining motion and appearance similarity.\n",
        "# The Hungarian algorithm is then applied to find the optimal matching between detections and existing tracks.\n",
        "# Unmatched detections create new tracks, and unmatched tracks may be deleted after a threshold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dffed99d",
      "metadata": {
        "id": "dffed99d"
      },
      "outputs": [],
      "source": [
        "# Q14. Why is real-time tracking important in many applications?\n",
        "\n",
        "# answer\n",
        "# Real-time tracking is crucial for applications like surveillance, autonomous driving, and sports analytics,\n",
        "# where immediate decision-making and fast response are required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faf3366c",
      "metadata": {
        "id": "faf3366c"
      },
      "outputs": [],
      "source": [
        "# Q15. Describe the prediction and update steps of a Kalman Filter.\n",
        "\n",
        "# answer\n",
        "# Prediction step: Estimates the next state and its uncertainty using the motion model.\n",
        "# Update step: Incorporates the new measurement to correct the prediction, reducing uncertainty."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da7d3571",
      "metadata": {
        "id": "da7d3571"
      },
      "outputs": [],
      "source": [
        "# Q16. What is a bounding box, and how does it relate to object tracking?\n",
        "\n",
        "# answer\n",
        "# A bounding box is a rectangle that encloses an object in an image or video frame.\n",
        "# In object tracking, bounding boxes are used to represent the location of the tracked object over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e7ab10d",
      "metadata": {
        "id": "8e7ab10d"
      },
      "outputs": [],
      "source": [
        "# Q17. What is the purpose of combining object detection and tracking in a pipeline?\n",
        "\n",
        "# answer\n",
        "# Combining detection and tracking provides accurate object localization (detection)\n",
        "# and consistent object identity over time (tracking),\n",
        "# improving robustness in dynamic environments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6aafbd52",
      "metadata": {
        "id": "6aafbd52"
      },
      "outputs": [],
      "source": [
        "# Q18. What is the role of the appearance feature extractor in DeepSORT?\n",
        "\n",
        "# answer\n",
        "# The appearance feature extractor generates a feature vector for each detected object.\n",
        "# These features help re-identify objects across frames, even after occlusion or appearance changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a505515",
      "metadata": {
        "id": "2a505515"
      },
      "outputs": [],
      "source": [
        "# Q19. How do occlusions affect object tracking, and how can Kalman Filter help mitigate this?\n",
        "\n",
        "# answer\n",
        "# Occlusions cause objects to disappear temporarily, leading to tracking loss or identity switches.\n",
        "# The Kalman Filter predicts the object's position during occlusion, helping maintain continuity until it reappears."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0e682a4",
      "metadata": {
        "id": "d0e682a4"
      },
      "outputs": [],
      "source": [
        "# Q20. Explain how YOLO's architecture is optimized for speed.\n",
        "\n",
        "# answer\n",
        "# YOLO processes the entire image in a single pass using a single convolutional neural network,\n",
        "# eliminating the need for region proposals, making it much faster than two-stage detectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a89e42f",
      "metadata": {
        "id": "1a89e42f"
      },
      "outputs": [],
      "source": [
        "# Q21. What is a motion model, and how does it contribute to object tracking?\n",
        "\n",
        "# answer\n",
        "# A motion model predicts the future position of an object based on its past positions and velocities.\n",
        "# It helps maintain tracking accuracy between detections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "010918d2",
      "metadata": {
        "id": "010918d2"
      },
      "outputs": [],
      "source": [
        "# Q22. How can the performance of an object tracking system be evaluated?\n",
        "\n",
        "# answer\n",
        "# Performance can be evaluated using metrics such as:\n",
        "# - MOTA (Multiple Object Tracking Accuracy)\n",
        "# - MOTP (Multiple Object Tracking Precision)\n",
        "# - ID switches\n",
        "# - Precision and recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61dd4ba5",
      "metadata": {
        "id": "61dd4ba5"
      },
      "outputs": [],
      "source": [
        "# Q23. What are the key differences between DeepSORT and traditional tracking algorithms?\n",
        "\n",
        "# answer\n",
        "# DeepSORT combines deep appearance features with motion models, making it more robust to occlusion and re-identification problems.\n",
        "# Traditional trackers often rely only on motion or simple features, leading to poorer performance in complex scenes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e47c50d",
      "metadata": {
        "id": "9e47c50d"
      },
      "source": [
        "# Practical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62d0937d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62d0937d",
        "outputId": "80d65d75-944d-4d17-cadf-6a1704f57122"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5\n",
            "4.25\n",
            "5.625\n",
            "7.3125\n",
            "8.65625\n"
          ]
        }
      ],
      "source": [
        "# Q1. Implement a Kalman filter to predict and update the state of an object given its measurements\n",
        "\n",
        "#code >\n",
        "import numpy as np\n",
        "\n",
        "class KalmanFilter:\n",
        "    def __init__(self, process_variance, measurement_variance, estimated_error, initial_value):\n",
        "        self.process_variance = process_variance\n",
        "        self.measurement_variance = measurement_variance\n",
        "        self.estimated_error = estimated_error\n",
        "        self.posteri_estimate = initial_value\n",
        "\n",
        "    def update(self, measurement):\n",
        "        # Prediction update\n",
        "        priori_estimate = self.posteri_estimate\n",
        "        priori_error_estimate = self.estimated_error + self.process_variance\n",
        "\n",
        "        # Measurement update\n",
        "        blending_factor = priori_error_estimate / (priori_error_estimate + self.measurement_variance)\n",
        "        self.posteri_estimate = priori_estimate + blending_factor * (measurement - priori_estimate)\n",
        "        self.estimated_error = (1 - blending_factor) * priori_error_estimate\n",
        "        return self.posteri_estimate\n",
        "\n",
        "#example\n",
        "kf = KalmanFilter(1, 2, 1, 0)\n",
        "measurements = [5, 6, 7, 9, 10]\n",
        "for m in measurements:\n",
        "    print(kf.update(m))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "866d272b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "866d272b",
        "outputId": "1dfdfb62-5b2d-4f31-bffd-a0100d7df392"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.50196078 1.        ]\n",
            " [0.25098039 0.75294118 0.50196078]]\n"
          ]
        }
      ],
      "source": [
        "# Q2. Write a function to normalize an image array such that pixel values are scaled between 0 and 1\n",
        "\n",
        "#code >\n",
        "import numpy as np\n",
        "\n",
        "def normalize_image(image_array):\n",
        "    return (image_array - np.min(image_array)) / (np.max(image_array) - np.min(image_array))\n",
        "\n",
        "#example\n",
        "img = np.array([[0, 128, 255], [64, 192, 128]])\n",
        "print(normalize_image(img))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf2343a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf2343a6",
        "outputId": "34eb3a76-0a59-4d22-fb36-4d9ab9ffe19b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Detections: [{'bbox': [84, 19, 1, 29], 'confidence': 0.9969024441932197}, {'bbox': [77, 41, 82, 66], 'confidence': 0.6563097797631068}, {'bbox': [22, 91, 47, 14], 'confidence': 0.51510866040086}, {'bbox': [26, 75, 14, 47], 'confidence': 0.19306410012079156}, {'bbox': [74, 72, 96, 95], 'confidence': 0.24977284356529328}]\n",
            "Filtered Detections: [{'bbox': [84, 19, 1, 29], 'confidence': 0.9969024441932197}, {'bbox': [77, 41, 82, 66], 'confidence': 0.6563097797631068}, {'bbox': [22, 91, 47, 14], 'confidence': 0.51510866040086}]\n"
          ]
        }
      ],
      "source": [
        "# Q3. Create a function to generate dummy object detection data with confidence scores and bounding boxes. Filter the detections based on a confidence threshold\n",
        "\n",
        "#code >\n",
        "import numpy as np\n",
        "\n",
        "def generate_dummy_detections(num_detections=5):\n",
        "    detections = []\n",
        "    for _ in range(num_detections):\n",
        "        bbox = np.random.randint(0, 100, size=4).tolist()  # [x1, y1, x2, y2]\n",
        "        confidence = np.random.random()\n",
        "        detections.append({'bbox': bbox, 'confidence': confidence})\n",
        "    return detections\n",
        "\n",
        "def filter_detections(detections, threshold=0.5):\n",
        "    return [d for d in detections if d['confidence'] >= threshold]\n",
        "\n",
        "#example\n",
        "dummy_data = generate_dummy_detections()\n",
        "print(\"All Detections:\", dummy_data)\n",
        "print(\"Filtered Detections:\", filter_detections(dummy_data, 0.5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a34baf71",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a34baf71",
        "outputId": "3932f4b1-2ed9-4b5c-95c3-c96a323ba6c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: array([0.80199013, 0.55776517, 0.24669209, 0.91864669, 0.14372925,\n",
            "       0.04217201, 0.20064902, 0.31570841, 0.1114638 , 0.96605977,\n",
            "       0.79249444, 0.21966658, 0.2254875 , 0.24441106, 0.95074161,\n",
            "       0.07968714, 0.36780852, 0.29177019, 0.78597214, 0.01578764,\n",
            "       0.59863715, 0.03467378, 0.69809078, 0.84477946, 0.15160425,\n",
            "       0.5556983 , 0.04498852, 0.07219799, 0.31963544, 0.54866504,\n",
            "       0.94038602, 0.51484796, 0.56905759, 0.03180249, 0.82691646,\n",
            "       0.90929974, 0.89591879, 0.18934859, 0.71927027, 0.11306687,\n",
            "       0.3454452 , 0.29926771, 0.05769887, 0.25100962, 0.58328043,\n",
            "       0.84003957, 0.7141282 , 0.04144319, 0.53187887, 0.4931658 ,\n",
            "       0.67347766, 0.55074416, 0.16263279, 0.53819634, 0.33796744,\n",
            "       0.75264489, 0.23632023, 0.22206079, 0.72803565, 0.87026163,\n",
            "       0.19896891, 0.23652469, 0.7781296 , 0.61227383, 0.67017025,\n",
            "       0.99266617, 0.66592728, 0.70243562, 0.96652693, 0.85215081,\n",
            "       0.47510266, 0.46382488, 0.8535735 , 0.13986441, 0.97987549,\n",
            "       0.27633038, 0.87486911, 0.67671263, 0.87750015, 0.36664861,\n",
            "       0.57230486, 0.40574532, 0.89967262, 0.32211054, 0.53715821,\n",
            "       0.61659761, 0.18888667, 0.7203733 , 0.3949094 , 0.59286972,\n",
            "       0.75060611, 0.34086215, 0.55782791, 0.63897427, 0.70075839,\n",
            "       0.29443241, 0.29378337, 0.99937102, 0.72988828, 0.31342339,\n",
            "       0.78278709, 0.89170688, 0.54620896, 0.59965188, 0.33550062,\n",
            "       0.26046933, 0.44838205, 0.39303747, 0.0115935 , 0.39450735,\n",
            "       0.29478861, 0.30860493, 0.52529102, 0.06727429, 0.05680816,\n",
            "       0.49319499, 0.38466145, 0.19754611, 0.02786208, 0.48638381,\n",
            "       0.68763802, 0.21412024, 0.04403689, 0.96286525, 0.30140341,\n",
            "       0.82901353, 0.3236724 , 0.78812302]), 1: array([5.68753824e-01, 4.08344725e-02, 8.02576506e-01, 6.13299704e-01,\n",
            "       4.13977128e-01, 5.47385388e-01, 4.33256928e-01, 7.50495071e-01,\n",
            "       5.27841983e-02, 5.67718477e-01, 7.29958183e-01, 5.24783924e-01,\n",
            "       5.29065442e-01, 8.87433779e-01, 8.93235693e-01, 7.51905233e-01,\n",
            "       9.39628492e-01, 4.80984693e-01, 9.16449004e-04, 9.36952308e-01,\n",
            "       8.71980779e-01, 8.25264450e-01, 7.66672966e-01, 8.98626054e-02,\n",
            "       5.21689861e-01, 9.34115312e-01, 9.59523524e-03, 3.76198971e-02,\n",
            "       3.15061713e-01, 6.32898049e-01, 4.40173806e-01, 1.16537042e-01,\n",
            "       4.40655029e-01, 4.56328482e-01, 7.72959198e-01, 9.41946471e-02,\n",
            "       9.66860839e-01, 1.81912461e-01, 4.83979770e-01, 7.09503017e-02,\n",
            "       3.58111945e-01, 2.42368413e-03, 7.23476262e-01, 4.26743405e-01,\n",
            "       4.78872250e-01, 7.40828164e-01, 9.83702271e-01, 7.06850851e-01,\n",
            "       2.39346775e-01, 7.50214170e-02, 9.03739481e-01, 2.27395617e-02,\n",
            "       3.56689274e-01, 5.54180221e-01, 3.17555076e-01, 3.68792304e-02,\n",
            "       5.84752590e-01, 7.57324002e-01, 5.66271348e-01, 2.94878058e-01,\n",
            "       3.22295802e-01, 9.27013862e-01, 8.74246013e-01, 9.81606579e-01,\n",
            "       5.75438596e-01, 7.70648178e-01, 2.60498194e-02, 9.15999117e-01,\n",
            "       7.27569005e-01, 8.84226226e-02, 8.74512451e-01, 2.15972175e-01,\n",
            "       9.58228285e-01, 6.68310624e-01, 8.34399445e-01, 3.16078902e-01,\n",
            "       9.00600517e-01, 3.30304919e-01, 3.30337182e-01, 2.21633636e-01,\n",
            "       8.83781127e-02, 4.75637857e-01, 5.12415948e-01, 6.25099501e-01,\n",
            "       9.43411246e-01, 5.96957787e-01, 6.51454968e-01, 9.75080568e-01,\n",
            "       8.92367767e-01, 2.79194814e-01, 2.98089403e-01, 9.64902943e-01,\n",
            "       4.66197791e-01, 6.20062182e-01, 2.65981792e-01, 9.33480476e-01,\n",
            "       7.38239395e-01, 8.59904386e-01, 5.40160036e-01, 9.01921414e-01,\n",
            "       1.80304842e-01, 3.00373010e-01, 8.15478178e-01, 3.25481038e-01,\n",
            "       6.57633318e-01, 3.14683391e-01, 7.25765331e-01, 5.50302675e-01,\n",
            "       7.85411096e-01, 8.90608214e-01, 8.19849751e-02, 7.94461121e-01,\n",
            "       4.04378775e-01, 8.81535282e-01, 7.07123468e-02, 2.23810820e-02,\n",
            "       9.05292724e-01, 3.36216153e-01, 1.87107613e-01, 3.16562280e-01,\n",
            "       7.10175953e-02, 2.32838587e-02, 9.76452075e-01, 2.93460836e-02,\n",
            "       1.76808014e-01, 3.70182144e-01, 1.93051766e-01, 2.11453959e-01])}\n"
          ]
        }
      ],
      "source": [
        "# Q4. Write a function that takes a list of YOLO detections and extracts a random 128-dimensional feature vector for each detection\n",
        "\n",
        "#code >\n",
        "import numpy as np\n",
        "\n",
        "def extract_features_yolo(detections):\n",
        "    features = {}\n",
        "    for i, det in enumerate(detections):\n",
        "        features[i] = np.random.random(128)  # random feature vector\n",
        "    return features\n",
        "\n",
        "#example\n",
        "yolo_detections = [{'bbox': [0,0,10,10]}, {'bbox': [5,5,15,15]}]\n",
        "print(extract_features_yolo(yolo_detections))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9aaf577",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9aaf577",
        "outputId": "d0d967d3-bf2d-49dd-bd0b-196cd1d078a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 1, np.float64(4.6305350919373955)), (1, 0, np.float64(4.715018158748601))]\n"
          ]
        }
      ],
      "source": [
        "# Q5. Write a function to re-identify objects by matching feature vectors based on Euclidean distance\n",
        "\n",
        "#code >\n",
        "import numpy as np\n",
        "\n",
        "def match_objects(features1, features2):\n",
        "    matches = []\n",
        "    for id1, vec1 in features1.items():\n",
        "        best_match = None\n",
        "        best_distance = float('inf')\n",
        "        for id2, vec2 in features2.items():\n",
        "            dist = np.linalg.norm(vec1 - vec2)\n",
        "            if dist < best_distance:\n",
        "                best_distance = dist\n",
        "                best_match = id2\n",
        "        matches.append((id1, best_match, best_distance))\n",
        "    return matches\n",
        "\n",
        "#example\n",
        "f1 = {0: np.random.random(128), 1: np.random.random(128)}\n",
        "f2 = {0: np.random.random(128), 1: np.random.random(128)}\n",
        "print(match_objects(f1, f2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4489bff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4489bff",
        "outputId": "5db42d71-9e2a-4ffc-91a3-c827f4b3bced"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([10., 20.]), array([15., 25.])]\n"
          ]
        }
      ],
      "source": [
        "# Q6. Write a function to track object positions using YOLO detections and a Kalman Filter\n",
        "\n",
        "#code >\n",
        "import numpy as np\n",
        "\n",
        "class SimpleKalman:\n",
        "    def __init__(self, init_pos):\n",
        "        self.pos = np.array(init_pos, dtype=float)\n",
        "\n",
        "    def predict(self):\n",
        "        return self.pos\n",
        "\n",
        "    def update(self, measurement):\n",
        "        self.pos = 0.5 * self.pos + 0.5 * np.array(measurement)\n",
        "        return self.pos\n",
        "\n",
        "def track_objects(detections):\n",
        "    trackers = [SimpleKalman(det['bbox'][:2]) for det in detections]\n",
        "    updated_positions = []\n",
        "    for t, det in zip(trackers, detections):\n",
        "        updated_positions.append(t.update(det['bbox'][:2]))\n",
        "    return updated_positions\n",
        "\n",
        "#example\n",
        "dets = [{'bbox': [10,20,30,40]}, {'bbox': [15,25,35,45]}]\n",
        "print(track_objects(dets))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eac6a25",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eac6a25",
        "outputId": "447f0f6e-072c-4183-fd4a-2563001ef0f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: [0. 0.] Updated: [-0.08313051 -1.70841668]\n",
            "Predicted: [-0.08313051 -1.70841668] Updated: [1.04756428 0.43290568]\n",
            "Predicted: [1.04756428 0.43290568] Updated: [1.70991897 0.9022283 ]\n",
            "Predicted: [1.70991897 0.9022283 ] Updated: [1.90521704 1.42385883]\n",
            "Predicted: [1.90521704 1.42385883] Updated: [2.95150452 2.29642814]\n"
          ]
        }
      ],
      "source": [
        "# Q7. Implement a simple Kalman Filter to track an object's position in a 2D space (simulate the object's movement with random noise)\n",
        "\n",
        "#code >\n",
        "import numpy as np\n",
        "\n",
        "class Kalman2D:\n",
        "    def __init__(self, process_var, measurement_var):\n",
        "        self.x = np.zeros(2)  # Initial position\n",
        "        self.P = np.eye(2) * 1000  # Initial uncertainty\n",
        "        self.F = np.eye(2)  # State transition\n",
        "        self.H = np.eye(2)  # Measurement function\n",
        "        self.R = np.eye(2) * measurement_var  # Measurement noise\n",
        "        self.Q = np.eye(2) * process_var  # Process noise\n",
        "\n",
        "    def predict(self):\n",
        "        self.x = self.F @ self.x\n",
        "        self.P = self.F @ self.P @ self.F.T + self.Q\n",
        "        return self.x\n",
        "\n",
        "    def update(self, z):\n",
        "        y = z - self.H @ self.x\n",
        "        S = self.H @ self.P @ self.H.T + self.R\n",
        "        K = self.P @ self.H.T @ np.linalg.inv(S)\n",
        "        self.x = self.x + K @ y\n",
        "        self.P = (np.eye(2) - K @ self.H) @ self.P\n",
        "        return self.x\n",
        "\n",
        "#example\n",
        "kf2d = Kalman2D(1, 4)\n",
        "for i in range(5):\n",
        "    prediction = kf2d.predict()\n",
        "    measurement = np.array([i + np.random.randn(), i + np.random.randn()])\n",
        "    print(\"Predicted:\", prediction, \"Updated:\", kf2d.update(measurement))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZQFXI9altnjD"
      },
      "id": "ZQFXI9altnjD",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}