{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e1ad886-5fab-4686-922a-b8f77c45912e",
   "metadata": {},
   "source": [
    "                            Detectron2 and TFOD 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a415046f-8443-478e-ad8c-4f4d458ca0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. What types of tasks does Detectron2 support?\n",
    "\n",
    "Detectron2 supports tasks such as object detection, instance segmentation,\n",
    "semantic segmentation, panoptic segmentation, and keypoint detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ea6084-b115-4f80-892e-b78e8c8fa649",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Why is data annotation important when training object detection models?\n",
    "\n",
    "Data annotation defines the locations and labels of objects in an image, \n",
    "which is crucial for training models to recognize and localize objects accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fa2d4c-4cb0-4367-8aea-d89099661211",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. What does batch size refer to in the context of model training?\n",
    "\n",
    "Batch size is the number of samples processed by the model in one forward\n",
    "and backward pass during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930134aa-d2c5-4482-988b-d5445a7f6a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. What is the purpose of pretrained weights in object detection models?\n",
    "\n",
    "Pretrained weights initialize a model with learned parameters from a similar task,\n",
    "reducing training time and improving performance on smaller datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5a24be-2b6b-4625-b564-08c5916aabda",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. How can you verify that Detectron2 was installed correctly?\n",
    "\n",
    "Run the following Python command to check the installation:\n",
    "\n",
    "import detectron2\n",
    "print(detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a824034-b91f-4c25-92f0-898c46dbf2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. What is TFOD2, and why is it widely used?\n",
    "\n",
    "TFOD2 (TensorFlow Object Detection API v2) is a library for training, deploying,\n",
    "and evaluating object detection models. It is popular due to its support for \n",
    "pretrained models, scalability, and TensorFlow ecosystem integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311a9574-05db-4bfd-9f40-ba500b95c5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. How does learning rate affect model training in Detectron2?\n",
    "\n",
    "Learning rate determines the step size for weight updates. A high learning\n",
    "rate can cause instability, while a low rate can slow down convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227c5f76-9117-4c5a-9db1-57c4480ea901",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. Why might Detectron2 use PyTorch as its backend framework?\n",
    "\n",
    "PyTorch offers dynamic computation graphs, ease of debugging, flexibility, \n",
    "and strong community support, making it suitable for research and deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd00c040-b9dd-436d-a5f4-9d6eb7ce3342",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. What types of pretrained models does TFOD2 support?\n",
    "\n",
    "TFOD2 supports models like SSD, Faster R-CNN, EfficientDet, and CenterNet, among others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060e17d2-3e9e-4541-8991-71603ef2db6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "10. How can data path errors impact Detectron2?\n",
    "\n",
    "Incorrect data paths can lead to issues in loading datasets, \n",
    "training failures, or incorrect evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e7cea4-3b2f-409a-8ddf-a27fd3a2ba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "11. What is Detectron2?\n",
    "\n",
    "Detectron2 is a PyTorch-based library for state-of-the-art object detection, \n",
    "segmentation, and other computer vision tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3847cd-cc9a-4730-bae3-dc18e7265225",
   "metadata": {},
   "outputs": [],
   "source": [
    "12. What are TFRecord files, and why are they used in TFOD2?\n",
    "\n",
    "TFRecord files are TensorFlow’s optimized format for storing large datasets.\n",
    "They allow faster reading and preprocessing during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bc00d5-a2eb-46f3-bc9e-327dc55f682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "13. What evaluation metrics are typically used with Detectron2?\n",
    "\n",
    "Metrics include mAP (mean Average Precision), precision, recall, and IoU (Intersection over Union)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be15c654-641c-472c-8ad5-004c130a4062",
   "metadata": {},
   "outputs": [],
   "source": [
    "14. How do you perform inference with a trained Detectron2 model?\n",
    "\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "# Load config and model weights\n",
    "cfg = get_cfg()\n",
    "cfg.MODEL.WEIGHTS = \"path_to_model_weights.pth\"\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# Perform inference\n",
    "image = cv2.imread(\"path_to_image.jpg\")\n",
    "outputs = predictor(image)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44dfc82-eaec-4798-b377-4a34fa6ce62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "15. What does TFOD2 stand for, and what is it designed for?\n",
    "\n",
    "TFOD2 stands for TensorFlow Object Detection API v2,\n",
    "designed for building, training, and deploying object detection models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90729c0-2b9e-4442-9d8f-839352a7dafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "16. What does fine-tuning pretrained weights involve?\n",
    "\n",
    "Fine-tuning involves adjusting the weights of a pretrained model on a \n",
    "specific dataset, optimizing performance for the target task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcdab84-c648-478d-a015-5ff0f177e8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "17. How is training started in TFOD2?\n",
    "\n",
    "Run the model_main_tf2.py script with appropriate configuration:\n",
    "\n",
    "python model_main_tf2.py --model_dir=path_to_model_dir --pipeline_config_path=path_to_pipeline.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3032e8-ef98-4baa-b813-45cc19e2f9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "18. What does COCO format represent, and why is it popular in Detectron2?\n",
    "\n",
    "COCO format is a standard dataset format for object detection and segmentation,\n",
    "featuring JSON files with image metadata, annotations, and categories. \n",
    "Its popularity comes from being comprehensive and widely supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58f06f9-b60c-4dc4-b6b0-4faf3441dc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "19. Why is evaluation curve plotting important in Detectron2?\n",
    "\n",
    "Evaluation curves visualize metrics like mAP, precision, \n",
    "and loss over training epochs, helping identify overfitting, \n",
    "underfitting, or optimization issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0845f5d1-00e8-4426-8e51-32319aa68980",
   "metadata": {},
   "outputs": [],
   "source": [
    "20. How do you configure data paths in TFOD2?\n",
    "\n",
    "Data paths are specified in the pipeline.config file under \n",
    "parameters like train_input_reader and eval_input_reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58abeb1d-7a62-425c-9a2b-e4c76ed5e018",
   "metadata": {},
   "outputs": [],
   "source": [
    "21. Can you run Detectron2 on a CPU?\n",
    "\n",
    "Yes, but it will be significantly slower than running on a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0b535b-d47a-4c54-8232-064718e87070",
   "metadata": {},
   "outputs": [],
   "source": [
    "22. Why are label maps used in TFOD2?\n",
    "\n",
    "Label maps map class indices to human-readable labels, ensuring\n",
    "consistent labeling during training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557cd46d-fb12-4a09-b81c-7ce36c5ed60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "23. What makes TFOD2 popular for real-time detection tasks?\n",
    "\n",
    "TFOD2 supports lightweight, efficient models like SSD and EfficientDet,\n",
    "which are optimized for real-time inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144d63da-0b99-4d00-8dfa-2b1414a9dabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "24. How does batch size impact GPU memory usage?\n",
    "\n",
    "Larger batch sizes require more GPU memory, as more data is processed simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6fd8d8-2852-4db1-9cf0-705fe0967506",
   "metadata": {},
   "outputs": [],
   "source": [
    "25. What's the role of Intersection over Union (IoU) in model evaluation?\n",
    "\n",
    "IoU measures the overlap between predicted and ground truth bounding boxes,\n",
    "quantifying localization accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4763406d-6602-4e4b-a914-57c9f1188011",
   "metadata": {},
   "outputs": [],
   "source": [
    "26. What is Faster R-CNN, and does TFOD2 support it?\n",
    "\n",
    "Faster R-CNN is a two-stage object detection model.\n",
    "TFOD2 supports it with various backbone configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c9926b-23aa-4b8d-8aaa-6ecee32bc770",
   "metadata": {},
   "outputs": [],
   "source": [
    "27. How does Detectron2 use pretrained weights?\n",
    "\n",
    "Detectron2 loads pretrained weights to initialize model\n",
    "parameters, which can be fine-tuned on new datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5036956e-2c95-4f5a-9fe1-cc4c2cf85b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "28. What file format is typically used to store training data in TFOD2?\n",
    "\n",
    "TFRecord format is commonly used for storing training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e5850d-4296-46ec-92ac-f48714256f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "29. What is the difference between semantic segmentation and instance segmentation?\n",
    "\n",
    "Semantic Segmentation: Labels each pixel with a class.\n",
    "Instance Segmentation: Labels pixels and distinguishes between\n",
    "individual instances of the same class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448347c1-b98d-4a2e-9d60-af008ed8f86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "30. Can Detectron2 detect custom classes during inference?\n",
    "\n",
    "Yes, provided the model is trained or fine-tuned with the custom classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa057757-f57b-4d5e-a0b3-87d0ad9d114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "31. Why is pipeline.config essential in TFOD2?\n",
    "\n",
    "pipeline.config specifies all configurations for model training,\n",
    "including data paths, hyperparameters, and model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10381af-e97d-4f04-9d97-3414333ab714",
   "metadata": {},
   "outputs": [],
   "source": [
    "32. What type of models does TFOD2 support for object detection?\n",
    "\n",
    "Models like SSD, Faster R-CNN, EfficientDet, CenterNet, and RetinaNet are supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a108b5-de66-4d71-9025-a16cb2c5f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "33. What happens if the learning rate is too high during training?\n",
    "\n",
    "The model may fail to converge, oscillate, or diverge entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c0d9e7-5ee8-4b65-967a-c5503b4f7812",
   "metadata": {},
   "outputs": [],
   "source": [
    "34. What is COCO JSON format?\n",
    "\n",
    "COCO JSON format is a standardized annotation format for object\n",
    "detection and segmentation datasets, storing image metadata and labeled bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f418c9-19d7-4669-bd16-7ca15b5c6b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "35. Why is TensorFlow Lite compatibility important in TFOD2?\n",
    "\n",
    "TensorFlow Lite compatibility enables deployment of models on \n",
    "mobile and edge devices, optimizing them for low-latency environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6568af0-ae85-401a-a301-063d87f8ae95",
   "metadata": {},
   "source": [
    "                              Practical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44db9fd1-2418-4e46-8b97-b3025e6b5e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. How do you install Detectron2 using pip and check the version of Detectron2?\n",
    "\n",
    "Install Detectron2 using the appropriate command for your environment (e.g., CUDA version).\n",
    "\n",
    "pip install 'detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu118/torch2.0/index.html'\n",
    "Check the version in Python:\n",
    "\n",
    "import detectron2\n",
    "print(detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b779bd-602f-4f6a-86a5-86196d25db17",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. How do you perform inference with Detectron2 using an online image?\n",
    "\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "import cv2\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# Load model config and weights\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"detectron2_repo/configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.MODEL.WEIGHTS = \"model_final_f10217.pkl\"\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# Load image from the web\n",
    "url = \"https://example.com/sample_image.jpg\"\n",
    "response = requests.get(url)\n",
    "image = Image.open(BytesIO(response.content))\n",
    "image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# Perform inference\n",
    "outputs = predictor(image)\n",
    "\n",
    "# Visualize results\n",
    "v = Visualizer(image[:, :, ::-1], scale=0.5)\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2.imshow(\"Detection\", out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967f49ad-979a-4071-8486-4b5ad2a2868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. How do you visualize evaluation metrics in Detectron2, such as training loss?\n",
    "\n",
    "During training, logs are saved in the output directory. Use TensorBoard to visualize metrics:\n",
    "\n",
    "tensorboard --logdir output_dir\n",
    "Alternatively, parse the logs using Python:\n",
    "\n",
    "from detectron2.utils.events import EventStorage\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# Parse logs from \"metrics.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56347e69-a632-404a-8b47-6fffd99956bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. How do you run inference with TFOD2 on an online image?\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "# Load pre-trained model\n",
    "model = tf.saved_model.load(\"path_to_saved_model\")\n",
    "\n",
    "# Load image from the web\n",
    "url = \"https://example.com/sample_image.jpg\"\n",
    "response = requests.get(url)\n",
    "image = Image.open(BytesIO(response.content))\n",
    "image_np = np.array(image)\n",
    "\n",
    "# Prepare input\n",
    "input_tensor = tf.convert_to_tensor(image_np)\n",
    "input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "# Perform inference\n",
    "detections = model(input_tensor)\n",
    "\n",
    "# Print results\n",
    "print(detections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211c91fd-2437-405a-a17a-6860f67bdfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. How do you install TensorFlow Object Detection API in Jupyter Notebook?\n",
    "\n",
    "Install the API using the following commands:\n",
    "\n",
    "!pip install tensorflow==2.12\n",
    "!pip install tensorflow-addons\n",
    "!git clone https://github.com/tensorflow/models.git\n",
    "%cd models/research\n",
    "!protoc object_detection/protos/*.proto --python_out=.\n",
    "!cp object_detection/packages/tf2/setup.py .\n",
    "!pip install .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76672412-41d2-42a6-9937-6f4691e5bb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. How can you load a pre-trained TensorFlow Object Detection model?\n",
    "\n",
    "import tensorflow as tf\n",
    "model = tf.saved_model.load(\"path_to_saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22202784-63e8-412f-a5d8-4f32cbe054ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. How do you preprocess an image from the web for TFOD2 inference?\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "# Load image from the web\n",
    "url = \"https://example.com/sample_image.jpg\"\n",
    "response = requests.get(url)\n",
    "image = Image.open(BytesIO(response.content))\n",
    "\n",
    "# Convert to NumPy array and normalize\n",
    "image_np = np.array(image)\n",
    "image_np = image_np / 255.0  # Normalize if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2d950a-a5ec-48b6-ba0e-eefa63b1f742",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. How do you visualize bounding boxes for detected objects in TFOD2 inference?\n",
    "\n",
    "Use TensorFlow’s visualization utilities:\n",
    "\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "\n",
    "# Visualize bounding boxes\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "    image_np,\n",
    "    detections['detection_boxes'],\n",
    "    detections['detection_classes'].numpy().astype(int),\n",
    "    detections['detection_scores'].numpy(),\n",
    "    category_index,\n",
    "    use_normalized_coordinates=True,\n",
    "    line_thickness=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ac7520-fc3b-4237-be51-94e5c9ac2f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. How do you define classes for custom training in TFOD2?\n",
    "\n",
    "Create a label_map.pbtxt file:\n",
    "\n",
    "item {\n",
    "  id: 1\n",
    "  name: 'class_name'\n",
    "}\n",
    "item {\n",
    "  id: 2\n",
    "  name: 'another_class'\n",
    "}\n",
    "\n",
    "Update the pipeline.config file to include the path to the label map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4f63f3-6fa0-4dd6-ad18-be5794d69c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "10. How do you resize an image before detecting objects?\n",
    "Use OpenCV or PIL to resize the image:\n",
    "\n",
    "import cv2\n",
    "resized_image = cv2.resize(image_np, (width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87fd38c-06e6-4ccd-aaa1-11c68e03d856",
   "metadata": {},
   "outputs": [],
   "source": [
    "11. How can you apply a color filter (e.g., red filter) to an image?\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Apply a red filter\n",
    "red_filter = np.zeros_like(image_np)\n",
    "red_filter[:, :, 2] = image_np[:, :, 2]  # Retain red channel\n",
    "red_image = cv2.addWeighted(image_np, 0.5, red_filter, 0.5, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
